module BetaRegression

using Distributions
using GLM
using LinearAlgebra
using LinearAlgebra.BLAS
using LogExpFunctions
using SpecialFunctions
using Statistics
using StatsAPI
using StatsBase
using StatsModels

# Necessary stuff that isn't exported from dependencies
using GLM: Link01, LmResp, cholpred, inverselink, linkfun, linkinv, mueta
using LinearAlgebra: copytri!
using StatsAPI: aic, aicc, bic, linearpredictor, linearpredictor!, offset, params
using StatsModels: TableRegressionModel, @delegate

export
    BetaRegressionModel,
    # Extensions/utilities from GLM:
    CauchitLink,
    CloglogLink,
    Link,
    Link01,
    LogitLink,
    ProbitLink,
    # Utilities from StatsModels:
    @formula,
    # Extensions from StatsAPI:
    aic,
    aicc,
    bic,
    coef,
    coefnames,
    coeftable,
    confint,
    deviance,
    devresid,
    dof,
    dof_residual,
    fit!,
    fit,
    fitted,
    informationmatrix,
    linearpredictor,
    loglikelihood,
    modelmatrix,
    nobs,
    offset,
    params,
    predict,
    r2,
    rÂ²,
    residuals,
    response,
    responsename,
    score,
    stderror,
    vcov,
    weights

"""
    BetaRegressionModel{T,L,V,M} <: RegressionModel

Type representing a regression model for beta-distributed response values in the open
interval (0, 1), as described by Ferrari and Cribari-Neto (2004).

The mean response is linked to the linear predictor by a link function with type
`L <: Link01`, i.e. the link must map ``(0, 1) â†¦ â„`` and use the GLM package's interface
for link functions.
"""
struct BetaRegressionModel{T<:AbstractFloat,L<:Link01,V<:AbstractVector{T},
                           M<:AbstractMatrix{T}} <: RegressionModel
    y::V
    X::M
    weights::Vector{T}
    offset::Vector{T}
    parameters::Vector{T}
    linearpredictor::Vector{T}
end

"""
    BetaRegressionModel(X, y, link=LogitLink(); weights=nothing, offset=nothing)

Construct a `BetaRegressionModel` object with the given model matrix `X`, response
`y`, link function `link`, and optionally `weights` and `offset`.

!!! warn
    Support for user-provided weights is currently incomplete; passing a value other
    than `nothing` or an empty array for `weights` will result in an error for now.
"""
function BetaRegressionModel(X::AbstractMatrix, y::AbstractVector,
                             link::Link01=LogitLink();
                             weights=nothing, offset=nothing)
    n, p = size(X)
    p < n || throw(ArgumentError("model matrix must have fewer columns than rows"))
    if n != length(y)
        throw(DimensionMismatch("model matrix and response have different numbers " *
                                "of observations"))
    end
    all(yáµ¢ -> 0 < yáµ¢ < 1, y) || throw(ArgumentError("response values must be 0 < y < 1"))
    T = promote_type(float(eltype(X)), float(eltype(y)))
    if weights === nothing
        weights = Vector{T}()
    else
        nw = length(weights)
        nw == 0 || throw(ArgumentError("user-provided weights are currently unsupported"))
    end
    if offset === nothing
        offset = Vector{T}()
    else
        no = length(offset)
        no == 0 || no == n || throw(ArgumentError("offset must be empty or have length $n"))
    end
    parameters = zeros(T, p + 1)
    Î· = Vector{T}(undef, n)
    _X = convert(AbstractMatrix{T}, X)
    _y = convert(AbstractVector{T}, y)
    return BetaRegressionModel{T,typeof(link),typeof(_y),typeof(_X)}(_y, _X, weights,
                                                                     offset, parameters, Î·)
end

function Base.show(io::IO, b::BetaRegressionModel{T,L}) where {T,L}
    print(io, """
          BetaRegressionModel{$T,$L}
              $(nobs(b)) observations
              $(dof(b)) degrees of freedom

          Coefficients:
          """)
    show(io, coeftable(b))
    return nothing
end

StatsAPI.response(b::BetaRegressionModel) = b.y

StatsAPI.modelmatrix(b::BetaRegressionModel) = b.X

StatsAPI.weights(b::BetaRegressionModel) = b.weights

StatsAPI.offset(b::BetaRegressionModel) = b.offset

StatsAPI.params(b::BetaRegressionModel) = b.parameters

StatsAPI.coef(b::BetaRegressionModel) = params(b)[1:(end - 1)]

"""
    precision(model::BetaRegressionModel)

Return the estimated precision parameter, ``\\phi``, for the model.
This parameter is estimated alongside the regression coefficients and is included in
coefficient tables.

See also: `coef`, `params`
"""
Base.precision(b::BetaRegressionModel) = params(b)[end]

StatsAPI.linearpredictor(b::BetaRegressionModel) = b.linearpredictor

function StatsAPI.linearpredictor!(b::BetaRegressionModel)
    X = modelmatrix(b)
    Î² = view(params(b), 1:size(X, 2))
    Î· = linearpredictor(b)
    if isempty(offset(b))
        mul!(Î·, X, Î²)
    else
        copyto!(Î·, offset(b))
        mul!(Î·, X, Î², true, true)
    end
    return Î·
end

StatsAPI.fitted(b::BetaRegressionModel) = linkinv.(Link(b), linearpredictor(b))

StatsAPI.residuals(b::BetaRegressionModel) = response(b) .- fitted(b)

StatsAPI.nobs(b::BetaRegressionModel) =
    isempty(weights(b)) ? length(response(b)) : count(>(0), weights(b))

StatsAPI.dof(b::BetaRegressionModel) = length(params(b))

StatsAPI.dof_residual(b::BetaRegressionModel) = nobs(b) - dof(b)

StatsAPI.r2(b::BetaRegressionModel) = cor(linearpredictor(b), linkfun.(Link(b), response(b)))^2

StatsAPI.predict(b::BetaRegressionModel) = fitted(b)

function StatsAPI.predict(b::BetaRegressionModel, newX::AbstractMatrix; offset=nothing)
    if !isempty(b.offset) && (offset === nothing || isempty(offset))
        throw(ArgumentError("model was fit with an offset but no offset was provided"))
    end
    Î·Ì‚ = newX * coef(b)
    if offset !== nothing && !isempty(offset)
        Î·Ì‚ .+= offset
    end
    return linkinv.(Link(b), Î·Ì‚)
end

GLM.Link(b::BetaRegressionModel{T,L}) where {T,L} = L()

function StatsAPI.coeftable(b::BetaRegressionModel; level::Real=0.95)
    Î¸ = params(b)
    se = stderror(b)
    z = Î¸ ./ se
    p = 2 * ccdf.(Normal(), abs.(z))
    ci = confint(b; level)
    level *= 100
    s = string(isinteger(level) ? trunc(Int, level) : level)
    return CoefTable(hcat(Î¸, se, z, p, ci),
                     ["Coef.", "Std. Error", "z", "Pr(>|z|)", "Lower $s%", "Upper $s%"],
                     push!(map(i -> "x$i", 1:(length(Î¸) - 1)), "(Precision)"), 4, 3)
end

function StatsAPI.confint(b::BetaRegressionModel; level::Real=0.95)
    Î¸ = params(b)
    se = stderror(b)
    side = se .* quantile(Normal(), (1 - level) / 2)
    return hcat(Î¸ .+ side, Î¸ .- side)
end

betalogpdf(Î¼, Ï•, y) = logpdf(Beta(Î¼ * Ï•, (1 - Î¼) * Ï•), y)

function StatsAPI.loglikelihood(b::BetaRegressionModel)
    y = response(b)
    Î¼ = fitted(b)
    Ï• = precision(b)
    w = weights(b)
    if isempty(w)
        return sum(i -> betalogpdf(Î¼[i], Ï•, y[i]), eachindex(y, Î¼))
    else
        return sum(i -> w[i] * betalogpdf(Î¼[i], Ï•, y[i]), eachindex(y, Î¼, w))
    end
end

function StatsAPI.loglikelihood(b::BetaRegressionModel, ::Colon)
    y = response(b)
    Î¼ = fitted(b)
    Ï• = precision(b)
    w = weights(b)
    if isempty(w)
        return map((yáµ¢, Î¼áµ¢) -> betalogpdf(Î¼áµ¢, Ï•, yáµ¢), y, Î¼)
    else
        return map((yáµ¢, Î¼áµ¢, wáµ¢) -> wáµ¢ * betalogpdf(Î¼áµ¢, Ï•, yáµ¢), y, Î¼, w)
    end
end

function StatsAPI.loglikelihood(b::BetaRegressionModel, i::Integer)
    y = response(b)
    @boundscheck checkbounds(y, i)
    Î· = linearpredictor(b)[i]
    Î¼ = linkinv(Link(b), Î·)
    Ï• = precision(b)
    â„“ = betalogpdf(Î¼, Ï•, y[i])
    isempty(weights(b)) || (â„“ *= weights(b)[i])
    return â„“
end

function GLM.devresid(b::BetaRegressionModel)
    Ï• = precision(b)
    return map(response(b), fitted(b)) do y, Î¼
        r = y - Î¼
        â„“â‚ = betalogpdf(y, Ï•, y)
        â„“â‚‚ = betalogpdf(Î¼, Ï•, y)
        return sign(r) * sqrt(2 * abs(â„“â‚ - â„“â‚‚))
    end
end

StatsAPI.deviance(b::BetaRegressionModel) = sum(abs2, devresid(b))

# Initialization method as recommended at the end of Ferrari (2004), section 2
"""
    initialize!(b::BetaRegressionModel)

Initialize the given [`BetaRegressionModel`](@ref) by computing starting points for
the parameter estimates and return the updated model object.
The initial estimates are based on those from a linear regression model with the same
model matrix as `b` but with `linkfun.(Link(b), response(b))` as the response.
"""
function initialize!(b::BetaRegressionModel)
    link = Link(b)
    X = modelmatrix(b)
    y = linkfun.(link, response(b))
    # We have to use the constructors directly because `LinearModel` supports an
    # offset but it isn't exposed by `lm`
    model = LinearModel(LmResp{typeof(y)}(zero(y), offset(b), weights(b), y),
                        cholpred(X, true))
    fit!(model)
    Î² = coef(model)
    Î· = fitted(model)
    n = nobs(model)
    k = length(Î²)
    e = sum(abs2, residuals(model)) / (n - k)
    Ï• = zero(eltype(Î²))
    for Î·áµ¢ in Î·
        Î¼áµ¢ = linkinv(link, Î·áµ¢)
        Ïƒáµ¢Â² = e * mueta(link, Î·áµ¢)^2
        Ï• += Î¼áµ¢ * (1 - Î¼áµ¢) / Ïƒáµ¢Â² - 1
    end
    Ï• /= n
    # No valid estimate for the precision, follow suit with `betareg` in R and set to 1
    # See https://stats.stackexchange.com/a/593670
    Ï• > 0 || (Ï• = one(Ï•))
    copyto!(params(b), push!(Î², Ï•))
    copyto!(linearpredictor(b), Î·)
    return b
end

function StatsAPI.score(b::BetaRegressionModel)
    X = modelmatrix(b)
    y = response(b)
    Î· = linearpredictor(b)
    link = Link(b)
    Ï• = precision(b)
    ÏˆÏ• = digamma(Ï•)
    âˆ‚Î¸ = zero(params(b))
    Tr = copy(Î·)
    @inbounds for i in eachindex(y, Î·)
        Î·áµ¢ = Î·[i]
        Î¼áµ¢ = linkinv(link, Î·áµ¢)
        yáµ¢ = y[i]
        a = digamma((1 - Î¼áµ¢) * Ï•)
        r = logit(yáµ¢) - digamma(Î¼áµ¢ * Ï•) + a
        âˆ‚Î¸[end] += Î¼áµ¢ * r + log(1 - yáµ¢) - a + ÏˆÏ•
        Tr[i] = Ï• * r * mueta(link, Î·áµ¢)
    end
    mul!(view(âˆ‚Î¸, 1:size(X, 2)), X', Tr)
    return âˆ‚Î¸
end

# Square root of the diagonal of the weight matrix, W for expected information (pg 7),
# Q for observed information (pg 10). `p = Î¼ * Ï•` and `q = (1 - Î¼) * Ï•` are the beta
# distribution parameters in the typical parameterization, `Ïˆâ€²_` is `trigamma(_)`.
function weightdiag(link, p, q, Ïˆâ€²p, Ïˆâ€²q, Ï•, yáµ¢, Î·áµ¢, dÎ¼dÎ·, expected)
    w = Ï• * (Ïˆâ€²p + Ïˆâ€²q)
    if expected
        return sqrt(w) * dÎ¼dÎ·
    else
        w *= dÎ¼dÎ·^2
        ystar = logit(yáµ¢)
        Î¼star = digamma(p) - digamma(q)
        w += (ystar - Î¼star) * dmueta(link, Î·áµ¢)
        return sqrt(w)
    end
end

# Fisher information, expected or observed, inverted or not. Used for computing the
# maximum likelihood estimates via Fisher scoring as well as for variance estimation.
# TODO: There's likely plenty of room for implementation improvement here in terms of
# speed and memory use.
function ðŸŸ(b::BetaRegressionModel, expected::Bool, inverse::Bool)
    X = modelmatrix(b)
    T = eltype(X)
    k = length(params(b))
    y = response(b)
    Î· = linearpredictor(b)
    link = Link(b)
    Ï• = precision(b)
    Ïˆâ€²Ï• = trigamma(Ï•)
    Tc = similar(Î·)
    w = similar(Î·)
    Î³ = zero(Ï•)
    for i in eachindex(y, Î·, w)
        Î·áµ¢ = Î·[i]
        Î¼áµ¢ = linkinv(link, Î·áµ¢)
        p = Î¼áµ¢ * Ï•
        q = (1 - Î¼áµ¢) * Ï•
        Ïˆâ€²p = trigamma(p)
        Ïˆâ€²q = trigamma(q)
        dÎ¼dÎ· = mueta(link, Î·áµ¢)
        w[i] = weightdiag(link, p, q, Ïˆâ€²p, Ïˆâ€²q, Ï•, y[i], Î·áµ¢, dÎ¼dÎ·, expected)
        Tc[i] = (Ïˆâ€²p * p - Ïˆâ€²q * q) * dÎ¼dÎ·
        Î³ += Ïˆâ€²p * Î¼áµ¢^2 + Ïˆâ€²q * (1 - Î¼áµ¢)^2 - Ïˆâ€²Ï•
    end
    Xáµ€ = copy(adjoint(X))
    Xáµ€Tc = Xáµ€ * Tc
    Xáµ€ .*= w'
    WX = copy(adjoint(Xáµ€))
    if inverse
        WX = qr!(WX)
        # constructing the equivalent choleky factor manually
        # because I haven't had time to rewrite the ldiv! and rdiv! code below
        Xáµ€WX = Cholesky(UpperTriangular(WX.R))
        # solving for A with Cholesky
        # A = Xáµ€WX \ Xáµ€Tc
        # solving for A with QR
        # XXX this should be more accurate than the Cholesky route, but we fail some tests
        # compared to reference values
        # However the pathological cases really need the numerical stability here
        # combined with the step halving to work
        A = WX \ Tc
        Î³ -= dot(A, Xáµ€Tc) / Ï•
        # Upper left block
        KÎ²Î² = copytri!(syrk('U', 'N', true, Xáµ€Tc), 'U')
        KÎ²Î² ./= Î³ * Ï•
        rdiv!(KÎ²Î², Xáµ€WX)
        for i in axes(KÎ²Î², 1)
            @inbounds KÎ²Î²[i, i] += 1
        end
        ldiv!(Xáµ€WX, KÎ²Î²)
        rdiv!(KÎ²Î², Ï•)
        # Upper right and lower left
        KÎ²Ï• = rdiv!(A, -Î³ * Ï•)
        # Lower right
        KÏ•Ï• = 1 / Î³
    else
        KÎ²Î² = syrk('U', 'N', Ï•, Xáµ€)
        KÎ²Ï• = Xáµ€Tc
        KÏ•Ï• = Î³
    end
    K = Matrix{T}(undef, k, k)
    copyto!(view(K, 1:(k - 1), 1:(k - 1)), Symmetric(KÎ²Î²))
    copyto!(view(K, 1:(k - 1), k), KÎ²Ï•)
    K[k, k] = KÏ•Ï•
    return Symmetric(K)
end

StatsAPI.informationmatrix(b::BetaRegressionModel; expected::Bool=true) =
    ðŸŸ(b, expected, false)

StatsAPI.vcov(b::BetaRegressionModel) = ðŸŸ(b, true, true)

function checkfinite(x, iters)
    if any(!isfinite, x)
        throw(ConvergenceException(iters, NaN, NaN,
                                   "Coefficient update contains infinite values."))
    end
    return nothing
end

"""
    fit!(b::BetaRegressionModel; maxiter=100, atol=1e-8, rtol=1e-8)

Fit the given [`BetaRegressionModel`](@ref), updating its values in-place. If model
convergence is achieved, `b` is returned, otherwise a `ConvergenceException` is thrown.

Fitting the model consists of computing the maximum likelihood estimates for the
coefficients and precision parameter via Fisher scoring with analytic derivatives.
The model is determined to have converged when the score vector, i.e. the vector of
first partial derivatives of the log likelihood with respect to the parameters, is
approximately zero. This is determined by `isapprox` using the specified `atol` and
`rtol`. `maxiter` dictates the maximum number of Fisher scoring iterations.
"""
function StatsAPI.fit!(b::BetaRegressionModel; maxiter=100, atol=1e-8, rtol=1e-8)
    initialize!(b)
    z = zero(params(b))
    scratch = similar(params(b))
    for iter in 1:maxiter
        U = score(b)
        checkfinite(U, iter)
        isapprox(U, z; atol, rtol) && return b  # converged!
        K = ðŸŸ(b, true, true)
        checkfinite(K, iter)
        if last(U) * precision(b) + precision(b) >= 0
            mul!(params(b), K, U, true, true)
        else
            copyto!(scratch, params(b))
            mul!(scratch, K, U, true, true)
            vv = params(b)
            vv .+= scratch
            vv ./= 2
        end
        linearpredictor!(b)
    end
    throw(ConvergenceException(maxiter))
end

"""
    fit(BetaRegressionModel, formula, data, link=LogitLink(); kwargs...)

Fit a [`BetaRegressionModel`](@ref) to the given table `data`, which may be any
Tables.jl-compatible table (e.g. a `DataFrame`), using the given `formula`, which can
be constructed using `@formula`. In this method, the response and model matrix are
determined from the formula and table. It is also possible to provide them explicitly.

    fit(BetaRegressionModel, X::AbstractMatrix, y::AbstractVector, link=LogitLink(); kwargs...)

Fit a beta regression model using the provided model matrix `X` and response vector `y`.
In both of these methods, a link function may be provided. If left unspecified, a
logit link is used.

## Keyword Arguments

- `weights`: A vector of weights or `nothing` (default). Currently only `nothing` is accepted.
- `offset`: An offset vector to be added to the linear predictor or `nothing` (default).
- `maxiter`: Maximum number of Fisher scoring iterations to use when fitting. Default is 100.
- `atol`: Absolute tolerance to use when checking for model convergence. Default is 1e-8.
- `rtol`: Relative tolerance to use when checking for convergence. Default is also 1e-8.
"""
function StatsAPI.fit(::Type{BetaRegressionModel}, X::AbstractMatrix, y::AbstractVector,
                      link=LogitLink(); weights=nothing, offset=nothing, maxiter=100,
                      atol=1e-8, rtol=1e-8)
    b = BetaRegressionModel(X, y, link; weights, offset)
    fit!(b; maxiter, atol, rtol)
    return b
end

# TODO: Move the StatsAPI extensions to the delegations that happen in StatsModels itself
@delegate(TableRegressionModel{<:BetaRegressionModel}.model,
          [Base.precision, GLM.Link, GLM.devresid, StatsAPI.informationmatrix,
           StatsAPI.linearpredictor, StatsAPI.offset, StatsAPI.score, StatsAPI.weights])

StatsAPI.responsename(m::TableRegressionModel{<:BetaRegressionModel}) =
    sprint(show, formula(m).lhs)

StatsAPI.coefnames(m::TableRegressionModel{<:BetaRegressionModel}) =
    vcat(coefnames(m.mf), "(Precision)")

# Define a more specific method than the one in StatsModels since that one calls
# `coeftable` on the model's `ModelFrame` directly and that will have too few
# coefficients
function StatsAPI.coeftable(m::TableRegressionModel{<:BetaRegressionModel}; kwargs...)
    ct = coeftable(m.model; kwargs...)
    ct.rownms = coefnames(m)
    return ct
end

"""
    dmueta(link::Link, Î·)

Return the second derivative of `linkinv`, ``dÂ²Î¼/dÎ·Â²``, of the link function `link`
evaluated at the linear predictor value `Î·`. A method of this function must be defined
for a particular link function in order to compute the observed information matrix.
"""
function dmueta end

dmueta(link::CauchitLink, Î·) = -2Ï€ * Î· * mueta(link, Î·)^2

dmueta(link::CloglogLink, Î·) = -expm1(Î·) * mueta(link, Î·)

function dmueta(link::LogitLink, Î·)
    Î¼, _, dÎ¼dÎ· = inverselink(link, Î·)
    return dÎ¼dÎ· * (1 - 2Î¼)
end

dmueta(link::ProbitLink, Î·) = -Î· * mueta(link, Î·)

end  # module
